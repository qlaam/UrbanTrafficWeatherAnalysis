# -*- coding: utf-8 -*-
"""traffic_cleaning_pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w23RL8IJiYgV9o4ISTZGeV9KwcSjhiyS
"""

# Commented out IPython magic to ensure Python compatibility.
# !git clone https://github.com/qlaam/UrbanTrafficWeatherAnalysis.git
# %cd UrbanTrafficWeatherAnalysis

import pandas as pd
import numpy as np

# Robust Date Parser
def parse_date_robust(date_str):
    if pd.isna(date_str):
        return np.nan

    s = str(date_str).strip()

    # Fix placeholder times
    s = s.replace("99:99", "00:00")
    s = s.replace("99:61", "00:01")

    # Normalize separators
    s = s.replace("T", " ").replace("Z", "").strip()

    # Fix multiple spaces
    while "  " in s:
        s = s.replace("  ", " ")

    # Fix zero month/day
    try:
        date_part, time_part = (s.split(" ") + ["00:00"])[:2]
        y, m, d = date_part.split("-")
        m = "01" if m == "00" else m
        d = "01" if d == "00" else d
        s = f"{y}-{m}-{d} {time_part}"
    except:
        pass

    # Try parsing
    parsed = pd.to_datetime(s, errors='coerce', utc=True)
    if pd.notna(parsed):
        return parsed.tz_convert(None)

    parsed = pd.to_datetime(s, errors='coerce', dayfirst=True, utc=True)
    if pd.notna(parsed):
        return parsed.tz_convert(None)

    return np.nan

# Pipeline Class
class TrafficCleaningPipeline:

    def __init__(self, input_path, output_path):
        self.input_path = input_path
        self.output_path = output_path

    def load(self):
        self.df = pd.read_csv(self.input_path)

    def clean_dates(self):
        self.df['date_time'] = self.df['date_time'].apply(parse_date_robust)
        median_date = self.df['date_time'].median()
        self.df['date_time'] = self.df['date_time'].fillna(median_date)

    def standardize_city(self):
        self.df['city'] = "London"

    def fix_numeric(self):
        numeric_cols = ["traffic_id", "vehicle_count", "avg_speed_kmh",
                        "accident_count", "visibility_m"]

        for col in numeric_cols:
            if col in self.df.columns:
                self.df[col] = pd.to_numeric(self.df[col], errors="coerce")

        self.df.loc[self.df['avg_speed_kmh'] < 0, 'avg_speed_kmh'] = np.nan

        for col in numeric_cols:
            self.df[col] = self.df[col].fillna(self.df[col].median())

    def fix_categories(self):
        mapping = {
            "low": "Low", "Low": "Low", "LOW": "Low",
            "medium": "Medium", "med": "Medium", "MID": "Medium",
            "high": "High", "HIGH": "High", "hi": "High",
        }

        self.df['congestion_level'] = (
            self.df['congestion_level']
            .astype(str)
            .str.strip()
            .map(lambda x: mapping.get(x, "Unknown"))
        )

        self.df['road_condition'] = self.df['road_condition'].astype(str).str.title()

        if "area" in self.df.columns:
            mode_area = self.df['area'].mode()[0]
            self.df['area'] = self.df['area'].fillna(mode_area)

    def clip_outliers(self):
        def clip_iqr(series, k=3):
            q1 = series.quantile(0.25)
            q3 = series.quantile(0.75)
            iqr = q3 - q1
            lower = q1 - k * iqr
            upper = q3 + k * iqr
            return series.clip(lower, upper)

        self.df['vehicle_count'] = clip_iqr(self.df['vehicle_count'])
        self.df['avg_speed_kmh'] = clip_iqr(self.df['avg_speed_kmh'])
        self.df['visibility_m'] = clip_iqr(self.df['visibility_m'])

    def dedupe(self):
        self.df = self.df.drop_duplicates()

    def save(self):
        self.df.to_parquet(self.output_path, index=False)

    def run(self):
        self.load()
        self.clean_dates()
        self.standardize_city()
        self.fix_numeric()
        self.fix_categories()
        self.clip_outliers()
        self.dedupe()
        self.save()
        print("Traffic cleaning completed.")
        print(f"Saved cleaned dataset â†’ {self.output_path}")

